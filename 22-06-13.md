## **2022년 6월 13일**

오늘은 소프트웨어 관련 기사 링크에 대해서 알아보았다.  
AI 바운드리스   마인드라는 기술을 AI 책임 연구소에서 연구하고 있다는 기사를 읽어보았다.  
이런 기사를 볼 때마다 소름이 돋을 정도로 인간의 기술이 얼마나 많이 발전하였는지를   
간접적으로 느낄 수 있었다.  

기사 내용에서는 AI의 윤리, 앞으로 소프트 웨어가 지킨다는 내용이 있었다.  
책임 있는 AI 연구소가 설립되어 AI의 윤리, 사생활 침해, 편견 문제 등을   기술적으로 푸는 연구를 하고 있다.  
AI 책임 연구소의 부사장은 컴퓨터 신경과학을 연구하고 인간의 뇌를 매핑하는   데에 많은 시간을 보냈다.  
그는 사람들이 어떻게 행동할지를 예측하기 위해 머신 러닝을 사용하는 데에 초점을 둔 바운드리스 마인드  
랩으로 첫 번째 스타트업을 끊었다.  

AI가 사회나 기술 조직에 해를 끼치지 않는 방식으로 책임감 있게  
이용되도록 AI 안전 문제를 다루고 있다. 또한 브라운 부사장은 연구계의 규정 준수를 위해 일하는 사람들은  
데이터 과학 팀과 대화하지 않고 무엇이 실제로 해를 끼치는지 알아내지 못하고 있다고 지적했다.  
기사에서는  비 윤리적 데이터가 사용되면, 워크플로우가 자동 정지되는 위반 시 워크플로우 자동 정지 시스템 
도 소개했다.  나는 이 기사를 굉장히 흥미롭게 읽었다.  

허나 나는 의문 하나가 들었다. 어떻게 워크플로우 시스템 하나로 비 윤리적 데이터가 사용되는 것을 막을 수 있을까? 악의적인 목적을 가진 사용자가 바운드리스 마인드 랩을 악용한다면 너무나도 쉽게 워크플로우 시스템의 보안이 뚫릴 수 있을거라고 생각했다. 바운드리스 마인드 랩같은 신세대 기술에 대한 뉴스를 가끔 볼 때면 인간의 기술이 얼마나 발전했는지 가늠할 수가 없다. 이런 AI 시스템에 대해서 나도 더욱 깊게 알아보고 싶고, 제일 처음의 AI 원리가 무엇인지도 더욱 깊게 알아보고 싶다. 또한 비 윤리적 데이터가 사용되는지를 워크플로우가 어떻게 판단하고 사용하는지에 대해서도 AI 머신 러닝 학습이 얼마나 발전했는지를 알 수 있다.  

이런 기술들이 빨리 발전하여 인간에게 큰 영향을 미쳤으면 좋겠고, 그에 대응하여 악용 방지 시스템도 철저히 구축하여 악용되어 피해를 입는 사례가 없으면 하는 바램이다. 시간이 난다면 AI의 원리에 대해서도 공부하고, 내가 개발할 웹/앱에 알고리즘 시스템이나 나쁜 키워드를 걸러주는 소소한 AI 시스템도 도입해보고싶다.  